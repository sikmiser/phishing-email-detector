
### README.md 

```markdown
## About This Project
This phishing detection project uses supervised and semi-supervised ML on the Enron email dataset. I built it to explore model performance (Naive Bayes, Logistic Regression, Random Forest) and learned data preprocessing, feature engineering, and evaluation along the way.

## My Journey
- **What I Did**: Wrote the initial model training (`phishing_detector_v2.py`), engineered features (urgency, URLs), and drove the project from concept to GitHub.
- **Collaboration**: Worked with an AI assistant (Grok from xAI) for debugging, code structuring, and Git commands—similar to pair programming or mentorship I’d seek in a team.
- **Growth**: Mastered Git, tackled semi-supervised learning, and learned to balance precision/recall—skills I’m excited to apply next!

## Skills Demonstrated
- Python, pandas, scikit-learn, Git
- Data preprocessing, feature engineering
- Model training, evaluation, debugging

# Phishing Email Detector

This project implements phishing email detection using machine learning on the Enron email dataset. It features two pipelines: a **supervised learning** approach with manually labeled data and a **semi-supervised learning** approach to scale labeling to a larger dataset. Three models—Naive Bayes, Logistic Regression, and Random Forest—are trained, evaluated, and compared to demonstrate their strengths and weaknesses in phishing detection. The project highlights data preprocessing, feature engineering, model training, and evaluation, offering insights into ML model selection.

## Features
- **Data Preparation**: Parses raw Enron emails into a structured CSV format.
- **Labeling**:
  - **Supervised**: Manually labels 50 emails (70% safe, 30% phishing).
  - **Semi-Supervised**: Extends labeling to 100 emails using a trained model.
- **Model Training**: Applies Naive Bayes, Logistic Regression, and Random Forest with custom features (urgency, URL presence, word count) and text vectorization via CountVectorizer.
- **Evaluation**: Computes accuracy, precision, recall, F1-score; generates confusion matrices and label distribution visualizations.

## Prerequisites
- **Python**: Version 3.8 or higher.
- **Dependencies**:
  - `pandas`: Data manipulation and CSV handling.
  - `scikit-learn`: Machine learning models, text vectorization, and evaluation metrics.
  - `matplotlib`: Plotting label distributions.
  - `seaborn`: Enhanced visualization of confusion matrices.
  - `re`: Regular expression support for feature extraction.
- **Input Files**:
  - `emails.csv`: Raw Enron email dataset (place in `~/Documents/ml_projects/`).
  - `enron_labeled.csv`: Optional 50 manually labeled emails (generated by script if not provided).

## Installation
Follow these steps to set up the project environment:

1. **Clone the Repository**:
   ```bash
   git clone https://github.com/yourusername/phishing-email-detector.git
   cd phishing-email-detector
   ```

2. **Install Python Dependencies**:
   - Install all required libraries using pip:
     ```bash
     pip install pandas scikit-learn matplotlib seaborn
     ```
   - Verify installation:
     ```bash
     python -c "import pandas, sklearn, matplotlib, seaborn, re; print('All dependencies installed!')"
     ```
     - Expected output: `All dependencies installed!`

3. **Prepare Input Files**:
   - Place `emails.csv` (Enron dataset) in `~/Documents/ml_projects/`.
   - If you have `enron_labeled.csv` (50 labeled emails), place it in `~/Documents/ml_projects/`; otherwise, it will be generated by `label_emails_manually.py`.

## Usage
Run the pipelines from the `~/Documents/ml_projects/` directory. Each script produces specific outputs, detailed below.

### Supervised Learning Pipeline
This pipeline uses manually labeled data to train models.

1. **Prepare Data**:
   ```bash
   python prepare_emails.py
   ```
   - **Input**: `emails.csv`
   - **Output**: `enron_sample.csv` (100 emails)
   - **Description**: Parses raw Enron emails into a clean CSV with `file` and `message` columns.
   - **Expected Terminal Output**:
     ```
     Sample CSV created at: /home/user/Documents/ml_projects/enron_sample.csv
     Number of emails: 100
     First email (raw): Message-ID: <18782981...
     ```

2. **Manually Label Emails**:
   ```bash
   python label_emails_manually.py
   ```
   - **Input**: `enron_sample.csv`
   - **Output**: `enron_labeled.csv` (50 labeled emails)
   - **Description**: Labels 50 emails (35 safe, 15 phishing) from the sample dataset.
   - **Expected Terminal Output**:
     ```
     Looking for file at: /home/user/Documents/ml_projects/enron_sample.csv
     CSV loaded successfully. Columns: ['file', 'message']
     Number of emails: 50
     First few emails: ["Message-ID: <18782981...
     First 5 emails and labels:
                                                text label
     0  Message-ID: <18782981...  safe
     ...
     ```

3. **Train and Evaluate Models**:
   ```bash
   python train_phishing_detector.py
   ```
   - **Input**: `enron_labeled.csv`
   - **Outputs**:
     - `results_v3.txt`: Model performance metrics (accuracy, precision, recall, F1-score).
     - `enron_predictions_v3.csv`: Test set predictions.
     - `confusion_matrices_v3.png`: Confusion matrix plots for each model.
     - `email_counts_v3.png`: Bar chart of label distribution.
   - **Description**: Trains and evaluates three models on the supervised dataset.
   - **Expected Terminal Output**:
     ```
     Loading data from: /home/user/Documents/ml_projects/enron_labeled.csv
     Data loaded. Columns: ['text', 'label']
     Naive Bayes Results:
     Accuracy: 0.80
     Precision: 1.00
     Recall: 0.33
     F1-Score: 0.50
     Confusion Matrix:
     [[7 0]
      [2 1]]
     Logistic Regression Results:
     Accuracy: 1.00
     ...
     ```

### Semi-Supervised Learning Pipeline
This pipeline scales labeling using a trained model.

1. **Prepare Data**:
   ```bash
   python prepare_emails.py
   ```
   - Same as supervised—outputs `enron_sample.csv`.

2. **Auto-Label Emails**:
   ```bash
   python auto_label_emails.py
   ```
   - **Inputs**: `enron_labeled.csv` (50 labeled), `enron_sample.csv` (100 emails)
   - **Output**: `enron_auto_labeled.csv` (100 labeled emails)
   - **Description**: Uses a Logistic Regression model trained on 50 labeled emails to predict labels for 100 emails.
   - **Expected Terminal Output**:
     ```
     Labeled data: 50 emails, Sample data: 100 emails
     Labeled columns: ['text', 'label']
     Sample columns: ['file', 'message']
     Auto-labeled 100 emails saved to: /home/user/Documents/ml_projects/enron_auto_labeled.csv
     Label distribution:
     label
     safe        72
     phishing    28
     Name: count, dtype: int64
     First 5 predictions:
                                                text label
     0  Message-ID: <18782981...  safe
     ...
     ```

3. **Train and Evaluate Models**:
   ```bash
   python train_phishing_detector_semi.py
   ```
   - **Input**: `enron_auto_labeled.csv`
   - **Outputs**:
     - `results_v3_semi.txt`: Model performance metrics (accuracy, precision, recall, F1-score).
     - `enron_predictions_v3_semi.csv`: Test set predictions.
     - `confusion_matrices_v3_semi.png`: Confusion matrix plots for each model.
     - `email_counts_v3_semi.png`: Bar chart of label distribution.
   - **Description**: Trains and evaluates three models on the semi-supervised dataset.
   - **Expected Terminal Output**:
     ```
     Loading data from: /home/user/Documents/ml_projects/enron_auto_labeled.csv
     Data loaded. Columns: ['text', 'label']
     Naive Bayes Results:
     Accuracy: 0.20
     Precision: 0.17
     Recall: 0.75
     F1-Score: 0.27
     Confusion Matrix:
     [[ 1 15]
      [ 1  3]]
     Logistic Regression Results:
     Accuracy: 0.80
     ...
     ```

## Results
### Supervised (50 emails, 70% safe, 30% phishing, 10 test emails)
- **Naive Bayes**: 
  - Accuracy: 80%, Precision: 1.00, Recall: 0.33, F1: 0.50
- **Logistic Regression**: 
  - Accuracy: 100%, Precision: 1.00, Recall: 1.00, F1: 1.00
- **Random Forest**: 
  - Accuracy: 100%, Precision: 1.00, Recall: 1.00, F1: 1.00
- **Note**: Small test set likely overfit—high accuracy reflects limited data.

### Semi-Supervised (100 emails, 72% safe, 28% phishing, 20 test emails)
- **Naive Bayes**: 
  - Accuracy: 20%, Precision: 0.17, Recall: 0.75, F1: 0.27
- **Logistic Regression**: 
  - Accuracy: 80%, Precision: 0.50, Recall: 1.00, F1: 0.67
- **Random Forest**: 
  - Accuracy: 75%, Precision: 0.40, Recall: 0.50, F1: 0.44
- **New Email Test** ('urgent act now get rich quick http://example.com'): All predict 'safe'—highlights generalization limits.

## Model Comparison
| Model              | Supervised Accuracy | Semi-Supervised Accuracy | Precision (Semi) | Recall (Semi) | F1 (Semi) | Strengths                          | Weaknesses                         | When to Use                       |
|--------------------|---------------------|--------------------------|------------------|---------------|-----------|------------------------------------|------------------------------------|-----------------------------------|
| Naive Bayes        | 80%                 | 20%                      | 0.17             | 0.75          | 0.27      | Fast, high recall, simple          | Low precision, over-predicts       | First-pass filter, high recall    |
| Logistic Regression| 100%                | 80%                      | 0.50             | 1.00          | 0.67      | High recall, interpretable         | Moderate precision, specific       | Security, some false positives OK |
| Random Forest      | 100%                | 75%                      | 0.40             | 0.50          | 0.44      | Robust, feature interactions       | Lower recall, overfit              | Diverse data, balanced needs      |

## Insights
- **Naive Bayes**: High recall makes it ideal for initial phishing detection where missing threats is costly, but low precision means many false positives—best as a pre-filter with manual review.
- **Logistic Regression**: Perfect recall in semi-supervised runs ensures no phishing is missed, with moderate precision—suitable for security applications where false positives can be tolerated.
- **Random Forest**: Balances precision and recall but underperforms on phishing recall here—needs more diverse data to leverage its robustness.
- **Lessons Learned**: Small supervised datasets overfit (100% accuracy), while semi-supervised scaling reveals real-world trade-offs. Generalization to overt phishing (e.g., URLs) requires broader training data.

## Project Structure
- `prepare_emails.py`: Parses raw Enron emails into `enron_sample.csv`.
- `label_emails_manually.py`: Manually labels 50 emails into `enron_labeled.csv` (supervised).
- `train_phishing_detector.py`: Trains and evaluates models on supervised data.
- `auto_label_emails.py`: Predicts labels for 100 emails into `enron_auto_labeled.csv` (semi-supervised).
- `train_phishing_detector_semi.py`: Trains and evaluates models on semi-supervised data.

## Outputs
- **Text Files**: `results_v3.txt`, `results_v3_semi.txt` (performance metrics).
- **CSV Files**: `enron_predictions_v3.csv`, `enron_predictions_v3_semi.csv` (test set predictions).
- **Plots**: 
  - `confusion_matrices_v3.png`, `confusion_matrices_v3_semi.png` (model performance visuals).
  - `email_counts_v3.png`, `email_counts_v3_semi.png` (label distributions).

## Future Improvements
- Scale to larger datasets (e.g., 1000+ emails) for robustness.
- Implement cross-validation for reliable evaluation.
- Explore advanced models (e.g., SVM, XGBoost) for comparison.
- Deploy as a Flask API for real-time phishing detection.

## Author
- Amanda McCumber

## License
MIT License
```
---
